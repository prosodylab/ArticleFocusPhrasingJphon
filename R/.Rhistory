summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std*Juncture +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
Juncture +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
#Juncture +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std*syntax +
logCondP.std +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std*syntax +
#logCondPTarget.std +
following_phone_label +
(1  | word_label) +
(1 | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax +
#logCondPTarget.std +
following_phone_label +
(syntax  | word_label) +
(LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax | Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax +
#logCondPTarget.std +
following_phone_label +
(syntax || word_label) +
(LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax || Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
# syntax +
#logCondPTarget.std +
following_phone_label +
(syntax || word_label) +
(LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax || Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
# syntax +
#logCondPTarget.std +
following_phone_label +
(1 | word_label) +
(LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
syntax || Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
system.time( # Model with random slope correlations has singular fit problem. Then, getting 0 correlation for Lg10WF.next.std, so removing.
model_full <- glmer( status ~
LogTargetWF.std +
LogFollowingWF.std +
logCondP.std +
# syntax +
#logCondPTarget.std +
following_phone_label +
(1 | word_label) +
(LogTargetWF.std +
LogFollowingWF.std +
logCondP.std  || Speaker)
, data=buckeye_nasal
, family="binomial"
, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=100000))
, verbose=2))
summary(model_full)
library(ggplot2)
library(tidyverse)
library(scales)
library(lme4)
library(languageR)
library(lmerTest)
setwd('/Users/chael/Google Drive/work/Projects/nasal_assimilation_git')
d=read.csv("buckeye_nasal_export_more_context.csv",sep = ",")
nrow(d)
#nsubset=filter(d,endsWith(word_label,'n'))
nAssimilated=filter(d,grepl('n$', word_label)&!grepl('mn$', word_label)&(phone_label=='m'| phone_label=='ng')&following_phone_label%in%c('p','k','b','g'))
nrow(nAssimilated)
nAssimilated$Status='Assimilated'
nNotAssimilated=filter(d,grepl('n$', word_label)&!grepl('mn$', word_label)&(phone_label=='n')&following_phone_label%in%c('p','k','b','g'))
nrow(nNotAssimilated)
nNotAssimilated$Status='Not Assimilated'
# attach(nAssimilated)
# assimilated=data.frame(status='assimmilated',previous_previous_previous_word_label,previous_previous_word_label,previous_word_label,word_label,following_word_label,following_following_word_label,following_following_following_word_label)
# detach(nAssimilated)
# notAssimilated=data.frame(status='notAssimmilated',word1=nNotAssimilated$word_label,word2=nNotAssimilated$following_word_label)
phrases=rbind(nAssimilated,nNotAssimilated)
# save list of all phrases with two words, first ending in 'n', second starting in p,b,k,g:
write.table(phrases,'phrases.txt',sep='\t',row.names=F)
# read in file with hand annotation of wether two words were seperated by a syntactic boundary:
phrasesWithJuncture=read.csv("phrases_withjuncture.txt",sep = "\t")
phrasesWithJuncture=filter(phrasesWithJuncture,syntax%in%c('0','1','2'))
phrasesWithJuncture$Juncture=ifelse(phrasesWithJuncture$syntax=='2',1,0)
# read in word frequencies
#freq=read.csv("SUBTLEXus74286wordstextversion.txt",sep = "\t")
freq=read.csv("SUBTLEXus74286wordstextversion_withZipf.txt",sep = "\t")
freq=data.frame(Word=freq$Word,SUBTLWF=freq$SUBTLWF)
# Code FollowingWord Frequency
phrasesWithJuncture$Word=phrasesWithJuncture$following_word_label
juncture=merge(phrasesWithJuncture,freq,all.x=TRUE,by=c("Word"),suffixes=c("",".other"))
names(juncture)[names(juncture) == 'SUBTLWF'] <- 'FollowingWF'
# Code Word Frequency
juncture$Word=juncture$word_label
juncture=merge(juncture,freq,all.x=TRUE,by=c("Word"),suffixes=c("",".other"))
names(juncture)[names(juncture) == 'SUBTLWF'] <- 'TargetWF'
juncture$status=ifelse(juncture$Status=='Assimilated',1,0)
## read in bigram frequencies
bigram=read.csv("w2c.txt",sep = "\t")
juncture$Sequence=paste(juncture$word_label,juncture$following_word_label)
bigram$Sequence = paste(bigram$a,bigram$a.1)
bigram=data.frame(Sequence=bigram$Sequence,BigramF=bigram$X268)
juncture=merge(juncture,bigram,all.x=TRUE,by=c("Sequence"),suffixes=c("",".other"))
juncture$BigramFpM=juncture$BigramF/400000000
#
juncture$CondProbFollowing=juncture$BigramFpM/juncture$TargetWF
juncture$CondProbTarget=juncture$BigramFpM/juncture$FollowingWF
juncture$Speaker=juncture$speaker_name
# standardize
juncture <- juncture %>%
mutate(
LogTargetWF.std=rescale(log10(TargetWF)),
LogFollowingWF.std=rescale(log10(FollowingWF)),
logCondP.std=rescale(log10(CondProb)),
logCondPTarget.std=rescale(log10(CondProbTarget))
)
# number of phonemes in target word:
juncture$phoneCount=str_count(juncture$word_transcription, " ")+1
juncture$wordLength.std=rescale((juncture$word_duration-juncture$phone_duration)/(juncture$phoneCount-1))
juncture$word_duration.std=rescale(juncture$word_duration)
ggplot(juncture,aes(x = factor(Juncture),fill = factor(Status))) + geom_bar(position = "fill") + scale_y_continuous(labels = percent_format()) + theme_gray(base_size = 18)
ggplot(juncture, aes(x=Status, y=FollowingWF)) +  stat_summary(fun.y = "mean", geom="bar")  + stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) + theme_bw(base_size = 18) + facet_grid(~Juncture)
ggplot(juncture,aes(y=status,x=FollowingWF),color="blue") +
stat_smooth(method="glm",method.args = list(family = "binomial")) +
ylim(0,1) +
geom_rug(position="jitter",sides="tb",alpha=.05,size=1,colour="black") +
stat_smooth(method="glm", method.args = list(family = "binomial"),aes(x=TargetWF),color="blue",linetype="dashed") +
#stat_smooth(method="gam", method.args = "family=binomial",aes(y=Glottaled,color=Glottaled),color="red") +
xlab("Frequency per million words (log scale)") +
ylab("Likelihood of Assimilation") +
theme_bw(base_size=10) + scale_x_log10(breaks=c(1,100,10000)) + facet_grid(~Juncture)
ggplot(juncture,aes(y=status,x=FollowingWF),color="blue") +
stat_smooth(method="glm",method.args = list(family = "binomial")) +
ylim(0,1) +
geom_rug(position="jitter",sides="tb",alpha=.05,size=1,colour="black") +
stat_smooth(method="glm", method.args = list(family = "binomial"),aes(x=TargetWF),color="blue",linetype="dashed") +
#stat_smooth(method="gam", method.args = "family=binomial",aes(y=Glottaled,color=Glottaled),color="red") +
xlab("Frequency per million words (log scale)") +
ylab("Likelihood of Assimilation") +
theme_bw(base_size=10) + scale_x_log10(breaks=c(1,100,10000)) + facet_grid(~syntax)
summary(juncture$status)
head(juncture)
ggplot(juncture,aes(y=status,x=CondProbFollowing),color="blue") +
stat_smooth(method="glm",method.args = list(family = "binomial")) +
ylim(0,1) +
geom_rug(position="jitter",sides="tb",alpha=.05,size=1,colour="black") +
#stat_smooth(method="glm", method.args = list(family = "binomial"),aes(x=TargetWF),color="blue",linetype="dashed") +
#stat_smooth(method="gam", method.args = "family=binomial",aes(y=Glottaled,color=Glottaled),color="red") +
xlab("Frequency per million words (log scale)") +
ylab("Likelihood of Assimilation") +
theme_bw(base_size=10) + scale_x_log10(breaks=c(1,100,10000)) + facet_grid(~syntax)
ggplot(juncture,aes(y=status,x=FollowingWF),color="blue") +
stat_smooth(method="glm",method.args = list(family = "binomial")) +
ylim(0,1) +
geom_rug(position="jitter",sides="tb",alpha=.05,size=1,colour="black") +
stat_smooth(method="glm", method.args = list(family = "binomial"),aes(x=TargetWF),color="blue",linetype="dashed") +
#stat_smooth(method="gam", method.args = "family=binomial",aes(y=Glottaled,color=Glottaled),color="red") +
xlab("Frequency per million words (log scale)") +
ylab("Likelihood of Assimilation") +
theme_bw(base_size=10) + scale_x_log10(breaks=c(1,100,10000)) + facet_grid(~syntax)
install.packages("MASS")
ginv(contr.treatment(3))
library(mass)
library('MASS')
ginv(contr.treatment(3))
contr.treatment(3)
ginv(contr.sum(3))
ginv(contr.helmert(3))
matrix(ginv(contr.helmert(3)))
contr.helmert(3)
30000*0.05
30000*1.32
30000*1.4
30000*0.08
40000*0.15
972.66/31970.14
176/12
14.2*2/3
library(ggplot2)
library(tidyverse)
library(scales)
library(lme4)
library(languageR)
library(lmerTest)
# Notes:
# MH: "I found a typo in an rnrOni sentence in condition 2 of item set 8; the relative pronouns "who" should be "that". This may have affected the grammaticality judgment..."
# woi annotation of 'semi-finals' not working right now due to hyphen
convertVariables <- function(df) {
# columns that are usually read as factors but should be numeric:
numericCols = c("duration", "silence", "duraSil", "phoneLength", "meanPitch", "maxPitch", "maxPitTime", "minPitch", "minPitTime", "pitch1", "pitch1_time", "pitch2", "pitch2_time", "pitch3", "pitch3_time", "pitch4", "pitch4_time", "pitch5", "pitch5_time", "pitch6", "pitch6_time", "pitch7", "pitch7_time", "pitch8", "pitch8_time", "pitch9", "pitch9_time", "pitch10", "pitch10_time", "meanIntensity", "maxIntensity", "maxIntTime", "intensity1", "intensity1_time", "intensity2", "intensity2_time", "intensity3", "intensity3_time", "intensity4", "intensity4_time", "intensity5", "intensity5_time", "intensity6", "intensity6_time", "intensity7", "intensity7_time", "intensity8", "intensity8_time", "intensity9", "intensity9_time", "intensity10", "intensity10_time", "zstart", "zend", "zDuration", "zPhonelength", "zmeanPitch", "zmaxPitch", "zmaxPitTime", "zminPitch", "zminPitTime", "zmeanIntensity", "zmaxIntensity", "zmaxIntTime", "response", "duration", "silence", "durasil", "meanpitch", "maxpitch", "maxPitTime", "minPitch", "minPitTime", "firstpitch", "secondpitch", "thirdpitch", "fourthpitch", "meanIntensity", "maxIntensity", "zduration", "zbeginzone", "zendzone", "zphonelength", "zmeanpitch", "zmaxpitch", "zmaxPitTime", "zminPitch", "zminPitTime", "zfirstpitch", "zsecondpitch", "zthirdpitch", "zfourthpitch", "zmeanIntensity", "zmaxIntensity", "durasil", "meanpit", "maxpitch", "maxPitTime", "minpitch", "minPitTime", "firstpitch", "secondpitch", "thirdpitch", "fourthpitch", "meanIntensity", "maxIntensity", "firstF1", "firstF2", "firstdif", "secondF1", "secondF2", "seconddif", "thirdF1", "thirdF2", "thirddif", "fourthF1", "fourthF2", "fourthdif", "fifthF1", "fifthF2", "fifthdif", "trialDuration", "response2")
nColumns = ncol(df)
# convert to numeric column, otherwise treat as factor:
for (i in 1:nColumns) {
if (colnames(df)[i] %in% numericCols) {
df[, i] <- as.numeric(as.character(df[, i]))
} else {
df[, i] <- as.factor(as.character(df[, i]))
}
}
return(df)
}
setwd('/Users/chael/Google\ Drive/work/Projects/masashiRNR/10_rnrM2/3_Ranalysis')
# drnrMi <- read.csv("../5_annotate_categorize_michael/rnrAg_rnrINF_rnrOn_rnrOni_rnrRER_responses_michael.txt",sep = "\t")
drnr <- read.csv("../5_annotate_categorize_michael/rnrAg_rnrINF_rnrOn_rnrOni_rnrRER_responses_michael.txt",sep = "\t")
drnr=convertVariables(drnr)
# rnr categorize Masashi:
drnrMa <- read.csv("../5_annotate_categorize_masashi/rnrAg_rnrINF_rnrOn_rnrOni_rnrRER_responses.txt",sep = "\t")
attach(drnrMa)
drnrMa=
data.frame(recordedFile,Masashi_rnr,
Masashi_quality,
Masashi_shift,
Masashi_comments)
detach(drnrMa)
drnr$proportionRNR_Michael=ifelse(drnr$Michael_rnr=='RNR',1,0)
drnr$proportionRNR_Masashi=ifelse(drnr$Masashi_rnr=='RNR',1,0)
# rnr boundary annotation Masashi:
drnrMa <- read.csv("../4_annotate/rnrAg_rnrINF_rnrOn_rnrOni_rnrRER_responses.txt",sep = "\t")
attach(drnrMa)
drnrMa=data.frame(recordedFile,Masashi_prominence, Masashi_boundary1, Masashi_boundary2,
Masashi_boundaryTone1, Masashi_boundaryTone2, Masashi_quality,
Masashi_misparsed, Masashi_comment_annotate=Masashi_comment, Masashi_truncated)
detach(drnrMa)
# merge with other data:
drnr=merge(drnr,drnrMa,all.x=TRUE,by=c("recordedFile"),suffixes=c("",".other"))
drnr$Boundary1=ifelse(drnr$Masashi_boundary1 %in% c('Strong','Weak '),1,0)
drnr$Boundary2=ifelse(drnr$Masashi_boundary2 %in% c('Strong ','Weak '),1,0)
drnr$Syntax=NA
drnr$Syntax='RNR'
drnr$Syntax[drnr$experiment=='rnrINF'&drnr$condition%in%c('3','4')]='FullSentence'
drnr$Syntax=factor(drnr$Syntax)
# this participant misunderstood task, redid experiment under number 09285
drnr=filter(drnr,participant!='9285')
length(unique(drnr$participant))
# experiment 1: Information status
# new vs. old
ggplot(filter(drnr,experiment=='rnrINF'), aes(x=InformationStatus, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
facet_grid(~Syntax) +
scale_fill_brewer(palette="Greens") +
xlab('')
# michael's annotation
ggplot(filter(drnr,experiment=='rnrINF'),
aes(x = InformationStatus,y = proportionRNR_Masashi)) +
stat_summary(fun.y=mean, geom="point",size=5, shape=1) +
stat_summary(fun.data = "mean_cl_boot", geom="errorbar",size=0.6, width=.15) +
stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,  position=position_dodge(width=0.9), hjust=-0.25)  +
coord_cartesian(ylim = c(0, 1)) + theme_bw(base_size = 20) +
facet_grid(~Syntax)
# by participant:
ggplot(filter(drnr,InformationStatus=='new'&experiment=='rnrINF'),
aes(x = Syntax,y = proportionRNR_Michael)) +
stat_summary(fun.y=mean, geom="point",size=5, shape=1) +
stat_summary(fun.data = "mean_cl_boot", geom="errorbar",size=0.6, width=.15) +
stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,  position=position_dodge(width=0.9), hjust=-0.25)  +
coord_cartesian(ylim = c(0, 1)) + theme_bw(base_size = 20) +
facet_wrap(~participant)
ggplot(filter(drnr,InformationStatus=='new'&experiment=='rnrINF'),
aes(x = Syntax,y = proportionRNR_Michael)) +
stat_summary(fun.y=mean, geom="point",size=5, shape=1) +
stat_summary(fun.data = "mean_cl_boot", geom="errorbar",size=0.6, width=.15) +
stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,  position=position_dodge(width=0.9), hjust=-0.25)  +
coord_cartesian(ylim = c(0, 1)) + theme_bw(base_size = 20)
# experiment 4
ggplot(filter(drnr,experiment=='rnrRER'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
# experiment 5
ggplot(filter(drnr,experiment=='rnrOni'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
ggplot(filter(drnr,experiment=='rnrOn'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
# experiment 5
ggplot(filter(drnr,experiment=='rnrOni'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
head(filter(drnr,experiment=='rnrOni'))
summary(filter(drnr,experiment=='rnrOni'))
ggplot(filter(drnr,experiment=='rnrOn'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
ggplot(filter(drnr,experiment=='rnrRER'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
head(filter(drnr,experiment=='rnrRER'))
ggplot(filter(drnr,experiment=='rnrRER'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')  +
facet_wrap(~participant)
# experiment 5
ggplot(filter(drnr,experiment=='rnrOni'&participant%in%c('2008','9282','1749','9284','9293','9292','9284','9171','9281','9149','1749','9293')), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
ggplot(filter(drnr,experiment=='rnrOni'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
# experiment 3
ggplot(filter(drnr,experiment=='rnrOn'&participant%in%c('2008','9282','1749','9284','9293','9292','9284','9171','9281','9149','1749','9293')), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('')
ggplot(filter(drnr,experiment=='rnrAg'), aes(x=Scope, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
scale_fill_brewer(palette="Greens") +
xlab('') + facet_wrap(~InformationStatus)
ggplot(filter(drnr,experiment=='rnrINF'), aes(x=InformationStatus, y=response)) +
geom_boxplot() +
scale_y_continuous(name="Naturalness", limits=c(0, 8)) +
theme_bw(base_size = 18) +
facet_grid(~Syntax) +
scale_fill_brewer(palette="Greens") +
xlab('')
# michael's annotation
ggplot(filter(drnr,experiment=='rnrINF'),
aes(x = InformationStatus,y = proportionRNR_Masashi)) +
stat_summary(fun.y=mean, geom="point",size=5, shape=1) +
stat_summary(fun.data = "mean_cl_boot", geom="errorbar",size=0.6, width=.15) +
stat_summary(aes(label=round(..y..,2)), fun.y=mean, geom="text", size=6,  position=position_dodge(width=0.9), hjust=-0.25)  +
coord_cartesian(ylim = c(0, 1)) + theme_bw(base_size = 20) +
facet_grid(~Syntax)
library(lme4)
library(lmerTest)
library(arm)
library(ggplot2)
library(lattice)
library(car)
library(sjPlot)
library(psych)
library(rpart)
library(rpart.plot)
library(party)
library(grid)
library(gridExtra)
library(tidyr)
library(dplyr)
library(xtable)
source('dimHelper.R')
source('dimDataPrep.R')
source('dimEDA_plots.R')
source('dimModels.R')
source('dimForest.R')
library(lme4)
library(lmerTest)
library(arm)
library(ggplot2)
library(lattice)
library(car)
library(sjPlot)
library(psych)
library(rpart)
library(rpart.plot)
library(party)
library(grid)
library(gridExtra)
library(tidyr)
library(dplyr)
library(xtable)
source('dimHelper.R')
