library(lme4)
library(lmerTest)
library(arm)
library(ggplot2)
library(reshape)
library(lattice)
library(plyr)
library(car)
library(sjPlot)
library(psych)
library(rpart)
library(rpart.plot)
library(grid)
library(gridExtra)


## Helper functions

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
                   .fun = function(xx, col) {
                       c(N    = length2(xx[[col]], na.rm=na.rm),
                         mean = mean   (xx[[col]], na.rm=na.rm),
                         sd   = sd     (xx[[col]], na.rm=na.rm)
                       )
                   },
                   measurevar
    )

    # Rename the "mean" column
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval:
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                           .fun = function(xx, col, na.rm) {
                               c(subjMean = mean(xx[,col], na.rm=na.rm))
                           },
                           measurevar,
                           na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
        mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}

summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

    # Ensure that the betweenvars and withinvars are factors
    factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                         FUN=is.factor, FUN.VALUE=logical(1))

    if (!all(factorvars)) {
        nonfactorvars <- names(factorvars)[!factorvars]
        message("Automatically converting the following non-factors to factors: ",
                paste(nonfactorvars, collapse = ", "))
        data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
    }

    # Get the means from the un-normed data
    datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                       na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

    # Drop all the unused columns (these will be calculated with normed data)
    datac$sd <- NULL
    datac$se <- NULL
    datac$ci <- NULL

    # Norm each subject's data
    ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

    # This is the name of the new column
    measurevar_n <- paste(measurevar, "_norm", sep="")

    # Collapse the normed data - now we can treat between and within vars the same
    ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                        na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

    # Apply correction from Morey (2008) to the standard error and confidence interval
    #  Get the product of the number of conditions of within-S variables
    nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                    FUN.VALUE=numeric(1)))
    correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

    # Apply the correction factor
    ndatac$sd <- ndatac$sd * correctionFactor
    ndatac$se <- ndatac$se * correctionFactor
    ndatac$ci <- ndatac$ci * correctionFactor

    # Combine the un-normed means with the normed results
    merge(datac, ndatac)
}


grid_arrange_shared_legend <- function(..., ncol = length(list(...)), nrow = 1, position = c("bottom", "right")) {
  
  plots <- list(...)
  position <- match.arg(position)
  g <- ggplotGrob(plots[[1]] + theme(legend.position = position))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  lwidth <- sum(legend$width)
  gl <- lapply(plots, function(x) x + theme(legend.position="none"))
  gl <- c(gl, ncol = ncol, nrow = nrow)
  
  combined <- switch(position,
                     "bottom" = arrangeGrob(do.call(arrangeGrob, gl),
                                            legend,
                                            ncol = 1,
                                            heights = unit.c(unit(1, "npc") - lheight, lheight)),
                     "right" = arrangeGrob(do.call(arrangeGrob, gl),
                                           legend,
                                           ncol = 2,
                                           widths = unit.c(unit(1, "npc") - lwidth, lwidth)))
  
  grid.newpage()
  grid.draw(combined)
  
  # return gtable invisibly
  invisible(combined)
  
}


setwd("/Users/chael/Dropbox/Projects/dimensions/9_JPhon/6_JPhon_Revision/R_Jphon")
# setwd("E:/Dropbox/dimensions/9_JPhon/6_JPhon_Revision/R_Jphon")

dannot=read.csv("all_responses.txt",sep='\t')

# load acoustic measures
ddOld = read.csv("pgdb_analysis.txt")
dd = read.csv("dimensions_syllable_export.csv")
dd.pitch = read.csv("dimensions_syllable_pitch_export.csv")
dd.intensity = read.csv("dimensions_syllable_intensity_export.csv")
dd <- merge(dd.pitch, dd.intensity)
# ggplot(dd0, aes(x=sound_file_structure, y=syllable_relativized_duration_by_speaker)) + geom_boxplot()+theme_bw(base_size = 22)  + facet_grid(~word_position_in_utterance)

#
#dd$participant=factor(as.numeric(unlist(regmatches(dd$speaker, gregexpr("[[:digit:]]+", dd$speaker)))))
dd$participant=dd$speaker
dd$experiment=factor(unlist(lapply(strsplit(as.character(dd$sound_file_name), "\\_"), "[", 1)))
dd$recordedFile=paste0(dd$sound_file_name,'.wav')

# merge acoustics with responses file
dd=merge(dd,dannot,all.x=TRUE,by=c('recordedFile'),suffixes=c("",".other"))

dd$itemOriginal=dd$item_original

dd$Item=factor(dd$itemOriginal)

numericCols=c("syllable_begin", "syllable_duration", "syllable_end", "syllable_position_in_word", "syllable_relativized_duration_by_speaker", "word_begin", "word_duration", "word_end", "word_position_in_utterance", "word_relativized_duration_by_speaker", "Mean_F0", "Mean_F0_relativized", "Stdev_F0", "Stdev_F0_relativized", "Median_F0", "Median_F0_relativized", "Max_F0", "Max_F0_relativized", "Min_F0", "Min_F0_relativized", "Mean_Intensity", "Mean_Intensity_relativized", "Stdev_Intensity", "Stdev_Intensity_relativized", "Median_Intensity", "Median_Intensity_relativized", "Max_Intensity", "Max_Intensity_relativized", "Min_Intensity", "Min_Intensity_relativized")

#
# a look at an example item set:
dd %>%
  filter(item=='4') %>%
  group_by(condition,text) %>%
  dplyr::summarise (n = n())  %>%
  as.data.frame


# adjust woi annotation:
dd$word_position_in_utterance[dd$condition%in%c(4)&dd$word_position_in_utterance!=1]=dd$word_position_in_utterance[dd$condition%in%c(4)&dd$word_position_in_utterance!=1]+2

nColumns = ncol(dd)
# convert to numeric column, otherwise treat as factor:
for (i in 1:nColumns) {
    if (colnames(dd)[i] %in% numericCols) {
        dd[, i] <- as.numeric(as.character(dd[, i]))
    } else {
        dd[, i] <- as.factor(as.character(dd[, i]))
    }
}


dd %>% group_by(experiment) %>% dplyr::summarise(length(unique(participant)))

participantsN=unique(dd$participant[dd$experiment=='suborn'])
participantsQ=unique(dd$participant[dd$experiment=='suborq'])
participantsBoth=participantsN[participantsN%in%participantsQ]

# only look at participants that were in both studies
dd=subset(dd,participant%in%participantsBoth)

# First and final syllable:
dd$Syllable=NA
dd$Syllable[dd$syllable_position_in_word=='1']='First'
dd$Syllable[dd$syllable_position_in_word=='3']='Last'
dd$Syllable[dd$Item=='1'&dd$word_position_in_utterance%in%c('5','6')&dd$syllable_position_in_word=='2']='Last'
dd$Syllable[dd$Item=='2'&dd$syllable_position_in_word=='2']='Last'
dd$Syllable[dd$Item=='4'&dd$word_position_in_utterance%in%c('5','6')&dd$syllable_position_in_word=='2']='Last'
dd$Syllable=factor(dd$Syllable)
# summary(factor(dd$Syllable[dd$woi%in%c('6','8','10')]))

# Focus coding:
dd$Focus=factor(recode(dd$condition,"'1'='Third';'2'='Second';'3'='First';'4'='Wide'"),levels=c('Wide','First','Second','Third'))
contrasts(dd$Focus)=cbind("Wide.vs.Narrow"=c(-3/4,1/4,1/4,1/4),"First.vs.Late"=c(0,-2/3,1/3,1/3),"Second.vs.Third"=c(0,0,-1/2,1/2))
dd$Wide.vs.Narrow=model.matrix(~ Focus,dd)[,2]
dd$First.vs.Late=model.matrix(~ Focus,dd)[,3]
dd$Second.vs.Third=model.matrix(~ Focus,dd)[,4]


#Intonation coding:
dd$Intonation[dd$experiment=="suborq"]="Interrogative"
dd$Intonation[dd$experiment=="suborn"]="Declarative"
dd$Intonation=factor(dd$Intonation)
contrasts(dd$Intonation)=cbind("Decl.vs.Inter"=c(-0.5,0.5))
dd$Decl.vs.Inter=model.matrix(~ Intonation,dd)[,2]

# in wide condition, renumber words for consistency
dd$woi=as.numeric(as.character(dd$word_position_in_utterance))
#dd$woi[dd$Focus=='Wide']=dd$woi[dd$Focus=='Wide']+4
dd$woi=factor(dd$woi)

# Coding of phrasing:
dd$Constituency[dd$bracketing=="l"]="(AB)C"
dd$Constituency[dd$bracketing=="r"]="A(BC)"
dd$Constituency=factor(dd$Constituency)
contrasts(dd$Constituency)=cbind("Left.vs.Right"=c(-0.5,0.5))
dd$Left.vs.Right=model.matrix(~ Constituency,dd)[,2]

# RA annotations
#
length(unique(dd$recordedFile))

# Problematic soundfiles: 86, 6.9% of the data
length(unique(dd$recordedFile[dd$Thea_problematic=='1'|dd$David_problematic=='1'|dd$Erin2_problematic=='1']))

# exclude files marked as problematic
dd=subset(dd,Thea_problematic!='1'&Thea_intonation!=4&Erin2_problematic!='1'&dd$David_problematic!='1')

# remove level 4='problematic' from Thea's intonation annotation:
dd$Thea_intonation=factor(dd$Thea_intonation)

length(unique(dd$recordedFile))
# remaining files: 1166/1253

# beginPause("What kind of response?")
# comment ("Where does the main prominence fall?")
# anno = choice ("intonation",3)
# option ("Falling")
# option ("Rising")
# option ("unclear")
# option ("problematic")
# anno = choice ("focus",5)
# option ("Wide Focus")
# option ("First")
# option ("Second")
# option ("Third")
# option ("unclear")
# anno = choice ("branching",3)
# option ("(a b) c")
# option ("a (b c)")
# option ("unclear")
# anno = boolean("problematic",0)
# clicked = endPause("Continue",1)

# "Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement."

# Intonation
dd$IntonationA1=mapvalues(dd$Thea_intonation,from=c("1", "2", "3", "4"),to=c("Falling", "Rising", "Unclear", NA))
dd$IntonationTest=mapvalues(dd$Erin2_intonation,from=c("1", "2", "3", "4"),to=c("Declarative", "Interrogative", NA, NA))
dd$IntonationA2=mapvalues(dd$Erin2_intonation,from=c("1", "2", "3", "4"),to=c("Falling", "Rising", "Unclear", NA))
# interrater agreement: 0.96 ('almost perfect')
cohen.kappa(x=cbind(dd$IntonationA1,dd$IntonationA2))

dd=ddply(dd,.(recordedFile),transform,IntonationCorrect=(Intonation==IntonationTest&!is.na(IntonationTest)))
# overall proportion of intonation annotation as expected based on annotation by A1: 0.963
nrow(dd[dd$IntonationCorrect,])/nrow(dd)

# intonation annotation breakdown:
subsIntonation=subset(dd,!is.na(IntonationA2))
subsIntonation=ddply(subsIntonation,.(experiment),transform,n=length(unique(recordedFile)))
ddply(subsIntonation,.(experiment,IntonationA2),summarise,number=length(unique(recordedFile)),proportion=(length(unique(recordedFile))/unique(n)))

# Prominence:
dd$ProminenceA1=mapvalues(dd$Thea_prominence,from=c("1", "2", "3","4","5"),to=c("Wide", "First", "Second","Third",NA))
dd$ProminenceA2=mapvalues(dd$Erin2_prominence,from=c("1", "2", "3", "4","5"),to=c("Wide", "First", "Second","Third",NA))
# Prominence: agreement 0.66 'substantial'
cohen.kappa(x=cbind(dd$ProminenceA1,dd$ProminenceA2))
#
dd=ddply(dd,.(recordedFile),transform,ProminenceCorrect=(Focus==ProminenceA2&!is.na(ProminenceA2)))
#
# overall proportion of prominence as expected, based on annotation by A1: 0.379
nrow(dd[dd$ProminenceCorrect,])/nrow(dd)

#
# Breakdown of proportions:
subsProminence=subset(dd,!is.na(ProminenceA2))
subsProminence=ddply(subsProminence,.(Focus),transform,n=length(unique(recordedFile)))
ddply(subsProminence,.(Focus,ProminenceA2),summarise,number=length(unique(recordedFile)),proportion=(length(unique(recordedFile))/unique(n)))




# Branching:
dd$ConstituencyA1=mapvalues(dd$Thea_branching,from=c("1", "2", "3"),to=c("(AB)C", "A(BC)", "Unclear"))
dd$ConstituencyA2=mapvalues(dd$Erin2_branching,from=c("1", "2", "3"),to=c("(AB)C", "A(BC)", "Unclear"))
# Branching: interrater reliability: 0.73 (substantial)
cohen.kappa(x=cbind(dd$ConstituencyA1,dd$ConstituencyA2))

dd=ddply(dd,.(recordedFile),transform,ConstituencyCorrect=(as.character(Constituency)==as.character(ConstituencyA2)&!is.na(ConstituencyA2)))
#
# overall proportion of constituency as expected based on annotation by A1: 0.610
#
nrow(dd[dd$ConstituencyCorrect,])/nrow(dd)

# breakdown of correct/incorect by levels:
subsConstituency=subset(dd,!is.na(ConstituencyA2))
subsConstituency=ddply(subsConstituency,.(Constituency),transform,n=length(unique(recordedFile)))
ddply(subsConstituency,.(Constituency,ConstituencyA2),summarise,number=length(unique(recordedFile)),proportion=(length(unique(recordedFile))/unique(n)))


# old woi annotation (now connectors have numbers too)
# I THOUGHT THEY SAID MARION_1 OR MARVIN_2 AND SARAH_3 ARRIVED BUT IN FACT THEY SAID THAT MARION_4 OR MARVIN_5 AND NOLAN_6 ARRIVED

# Manipulation in the Experiment:
# 1: Intonation: Declarative vs. Interrogative (i.e., polar question)
# 2: Focus: Which word is focused? Wide focus on entire coordinate structure vs. First (=woi 9), Second (=woi 11), or Third (=woi12)
# 3: Constituency: Do first two conjuncts form a constituent or the second two conjuncts?

# Manipulation 1 (intonation) was done between 2 sub-experiments; 2 (Focus) & 3 (Constituency) were within a single experiment

# There were 4 item sets
length(unique(dd$itemOriginal))
ddply(dd,.(itemOriginal,experiment,Constituency,Focus,Intonation),summarise,length(condition))

# There were 27 participants in the declarative and 31 in the interrogative experiment
# almost all participated in both experiments
ddply(dd,.(experiment),summarise,length(unique(participant)))


# subset of only the second clause

# here we only look at the three NPs (Names):
dd2=subset(dd,word_position_in_utterance%in%c('4','5','6'))

dd2$Position=factor(recode(dd2$word_position_in_utterance,"'4'='A';'5'='B';'6'='C'"))
contrasts(dd2$Position)=cbind("First.vs.Late"=c(2/3,-1/3,-1/3),"Second.vs.Third"=c(0,0.5,-0.5))
dd2$PosFirst.vs.Late=model.matrix(~ Position,dd2)[,2]
dd2$PosSecond.vs.Third=model.matrix(~ Position,dd2)[,3]

dd1=subset(dd2,Syllable=='First')
dd2=subset(dd2,Syllable=='Last')

# ddply(dd2,.(recordedFile,woi),summarise,length(condition))

# create 'wide' data frame with one row per utterance

# dput(names(dd2))
# columns in dd2 that vary depending on woi
varyColumns=c("syllable_label", "syllable_begin", "syllable_duration", "syllable_end", "syllable_position_in_word", "syllable_relativized_duration_by_speaker", "word_label", "word_begin", "word_duration", "word_end", "word_position_in_utterance", "word_relativized_duration_by_speaker", "Mean_F0", "Mean_F0_relativized", "Stdev_F0", "Stdev_F0_relativized", "Median_F0", "Median_F0_relativized", "Max_F0", "Max_F0_relativized", "Min_F0", "Min_F0_relativized", "Mean_Intensity", "Mean_Intensity_relativized", "Stdev_Intensity", "Stdev_Intensity_relativized", "Median_Intensity", "Median_Intensity_relativized", "Max_Intensity", "Max_Intensity_relativized", "Min_Intensity", "Min_Intensity_relativized","Position", "PosFirst.vs.Late", "PosSecond.vs.Third")

# 
dd1.wide=reshape(dd1,idvar=c("experiment", "participant","item","condition"),
                v.names=varyColumns,
                timevar=c("woi"),direction="wide")
dd2.wide=reshape(dd2,idvar=c("experiment", "participant","item","condition"),
                v.names=varyColumns,
                timevar=c("woi"),direction="wide")


### Create Residuals for each dimension by fitting model which includes all the othe predictors except the one of interest
## (for plotting purposes)

# columns with acoustic measures that should be residualized:
acousCol=c("syllable_begin", "syllable_duration", "syllable_end","syllable_relativized_duration_by_speaker", "word_begin", "word_duration", "word_end", "word_position_in_utterance", "word_relativized_duration_by_speaker", "Mean_F0", "Mean_F0_relativized", "Stdev_F0", "Stdev_F0_relativized", "Median_F0", "Median_F0_relativized", "Max_F0", "Max_F0_relativized", "Min_F0", "Min_F0_relativized", "Mean_Intensity", "Mean_Intensity_relativized", "Stdev_Intensity", "Stdev_Intensity_relativized", "Median_Intensity", "Median_Intensity_relativized", "Max_Intensity", "Max_Intensity_relativized", "Min_Intensity", "Min_Intensity_relativized")

colnames(dd1)[acousCol]

#
# Calculate Residuals
#

dataSets=c('dd1','dd2')

# 
for (syllableData in dataSets ) {
# Compute measures after controlling for intensity:
resid=get(syllableData)
for (acousticMeasure in acousCol) {
  print(paste('Fitting intensity residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                  scale(Mean_Intensity)+(1|participant)+(1|itemOriginal),
                  na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
resid.wide=reshape(resid,
                   idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                   v.names=varyColumns,
                   timevar="woi",direction="wide")
assign(paste('intensityOut_',syllableData,sep=''),resid)
assign(paste('intensityOutWide_',syllableData,sep=''),resid.wide)

# residuals based on using Max_F0 as predictor:
resid=get(syllableData)
#
for (acousticMeasure in acousCol) {
  print(paste('Fitting pitch residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                            scale(Max_F0)+(1|participant) +
                            (1|itemOriginal),
                            na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
#
resid.wide=reshape(resid,
                idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                v.names=varyColumns,
                timevar="woi",direction="wide")
assign(paste('pitchOut_',syllableData,sep=''),resid)
assign(paste('pitchOutWide_',syllableData,sep=''),resid.wide)

# Residuals for focus
resid=get(syllableData)
#
for (acousticMeasure in acousCol) {
  print(paste('Fitting focus residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                Constituency*Intonation*Position +
                (1|participant)+(1|itemOriginal),
                na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
resid.wide=reshape(resid,
                   idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                   v.names=varyColumns,
                   timevar="woi",direction="wide")
assign(paste('focus_',syllableData,sep=''),resid)
assign(paste('focusWide_',syllableData,sep=''),resid.wide)

#  Residuals for bracketing
resid=get(syllableData)
#
for (acousticMeasure in acousCol) {
  print(paste('Fitting bracketing residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                               Focus*Intonation*Position+
                               (Focus|participant)+(1|itemOriginal),
                               ,na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
#
resid.wide=reshape(resid,
                   idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                   v.names=varyColumns,
                   timevar="woi",direction="wide")
assign(paste('bracketing_',syllableData,sep=''),resid)
assign(paste('bracketingWide_',syllableData,sep=''),resid.wide)

# residuals for intonation
resid=get(syllableData)
#
for (acousticMeasure in acousCol) {
  print(paste('Fitting intonation residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                            Focus*Constituency*Position+
                            (1|participant)+(1|itemOriginal),
                            data=resid,na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
#
resid.wide=reshape(resid,
                   idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                   v.names=varyColumns,
                   timevar="woi",direction="wide")
assign(paste('intonation_',syllableData,sep=''),resid)
assign(paste('intonationWide_',syllableData,sep=''),resid.wide)

# residuals for position
resid=get(syllableData)
#
for (acousticMeasure in acousCol) {
  print(paste('Fitting position residuals for: ',syllableData,'$',acousticMeasure))
  # Model to compute residuals:
  model.lm = with(resid,lmer(get(acousticMeasure) ~
                            Focus*Constituency*Intonation+
                            (1|participant)+(1|itemOriginal),
                            data=resid,na.action=na.exclude))
  modelResiduals = resid(model.lm)
  resid[acousticMeasure]=as.matrix(modelResiduals)
}
#
resid.wide=reshape(resid,
                   idvar=c("experiment", "participant","item","condition", "syllable_position_in_word"),
                   v.names=varyColumns,
                   timevar="woi",direction="wide")
assign(paste('position_',syllableData,sep=''),resid)
assign(paste('position_',syllableData,sep=''),resid.wide)
}


#


##
## Plots and Analysis: Constituency
##

## for unresidualized plot:
# subset=data.long


# Pitch (thirdpitch seems to work best for phrasing cues--but this choicepoint should be motivated/understood better)
# Plots with lines to evoke that these are very stylized pitch tracks

plotwid=1.5
altplotwid=2.5
plotheight=2.7


######## Plots and analysis for Word B (Jphon)


subsetB=subset(dd2,Position=='B')
# model for subset in which everything was accurately perceived, and focus was on the first constituent:
accuB=subset(subsetB,ProminenceCorrect&Focus=='First')

nrow(subset(subsetB,Focus=='First'))
nrow(accuB)

##### xxx Duration analysis

# Relativized duration of first syllable
rel.dur.plot <- ggplot(dd1, aes(x=Position, y=syllable_relativized_duration_by_speaker,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10) + ggtitle('Relativized Duration') + theme(plot.title = element_text(hjust = 0.5)) + xlab('') #+ theme(legend.position="none") 
rel.dur.plot
#ggsave(file='../plots/DurationRelativized.pdf',width=3,height=3)

# Duration residualized for predictors other than phrasing
res.dur.plot <- ggplot(bracketing_dd2, aes(x=Position, y=syllable_relativized_duration_by_speaker,shape=Focus)) +
  stat_summary(fun.y=mean, geom="point") +
  #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
  stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) +
  ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Residualized Duration') + theme(plot.title = element_text(hjust = 0.5)) + ylab('Residualized Duration') + xlab('') + ylab(' (z-score)') #+ theme(legend.position="none")
res.dur.plot

# ggsave(file='../plots/DurationResidualized.pdf',width=3,height=3)



#pdf("../plots/DurationCombined.pdf",width=5,height=3, onefile=FALSE)
#grid_arrange_shared_legend(rel.dur.plot, res.dur.plot, ncol = 2, nrow = 1)
#dev.off()


durationModel=lmer(relative_duration~Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||Item)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||participant),data=subsetB,na.action=na.exclude)
summary(durationModel)

durationModelFirst=lmer(relative_duration~Decl.vs.Inter*Left.vs.Right+(Decl.vs.Inter*Left.vs.Right||Item)+(Decl.vs.Inter*Left.vs.Right||participant),data=accuB,na.action=na.exclude)
summary(durationModelFirst)

sink("../models/modelsDuration.tex", append=FALSE, split=FALSE)
texreg(list(durationModel,durationModelFirst),custom.model.names=c("All","Initial Focus"),naive=TRUE,single.row = T,include.aic=F,include.deviance=F,include.bic=F, include.loglik=F,include.variance=F,dcolumn=T, include.nobs=F, include.groups=F,,caption = "Mixed Effects Regression Models for the duration of word B.",use.packages=F,float.pos="h!",fontsize = "footnotesize",label="modelDuration")
sink()


##### xxx Pitch analysis

# Relativized pitch
rel.pitch.plot <- ggplot(dd1, aes(x=Position, y=Max_F0,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10) + ggtitle('Relativized Pitch') + theme(plot.title = element_text(hjust = 0.5)) + xlab('') #+ theme(legend.position="none") 
rel.pitch.plot
#ggsave(file='../plots/PitchRelativized.pdf',width=3,height=3)

# pitch residualized for predictors other than phrasing
res.pitch.plot <- ggplot(bracketing_dd1, aes(x=Position, y=Mean_F0_relativized,shape=Focus)) +
  stat_summary(fun.y=mean, geom="point") +
  #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
  stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) +
  ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Residualized Pitch') + theme(plot.title = element_text(hjust = 0.5)) + ylab('Residualized Pitch') + xlab('') + ylab(' (z-score)') #+ theme(legend.position="none")
res.pitch.plot
#ggsave(file='../plots/PitchResidualized.pdf',width=3,height=3)

pdf("../plots/PitchCombined.pdf",width=5,height=3, onefile=FALSE)
grid_arrange_shared_legend(rel.pitch.plot, res.pitch.plot, ncol = 2, nrow = 1)
dev.off()

pitchModel=lmer(relative_pitch~Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||Item)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||participant),data=subsetB,na.action=na.exclude)
summary(pitchModel)

pitchModelFirst=lmer(relative_pitch~Decl.vs.Inter*Left.vs.Right+(Decl.vs.Inter*Left.vs.Right||Item)+(Decl.vs.Inter*Left.vs.Right||participant),data=accuB)
summary(pitchModelFirst)

sink("../models/modelsPitch.tex", append=FALSE, split=FALSE)
texreg(list(pitchModel,pitchModelFirst),custom.model.names=c("All","Initial Focus"),naive=TRUE,single.row = T,include.aic=F,include.deviance=F,include.bic=F, include.loglik=F,include.variance=F,dcolumn=T, include.nobs=F, include.groups=F,,caption = "Mixed Effects Regression Models for the relativized pitch of word B.",use.packages=F,float.pos="h!",fontsize = "footnotesize",label="modelPitch")
sink()


##### xxx intensity analysis

# Relativized intensity
rel.intens.plot <- ggplot(dd1, aes(x=Position, y=Mean_Intensity,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10) + ggtitle('Relativized Intensity') + theme(plot.title = element_text(hjust = 0.5)) + xlab('') #+ theme(legend.position="none") 
rel.intens.plot
#ggsave(file='../plots/IntensityRelativized.pdf',width=3,height=3)

# Intensity residualized for predictors other than phrasing
res.intens.plot <- ggplot(bracketing_dd2, aes(x=Position, y=Mean_Intensity,shape=Focus)) +  stat_summary(fun.y=mean, geom="point") +
  #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
  stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) +
  ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Residualized Intensity') + theme(plot.title = element_text(hjust = 0.5)) + ylab('Residualized Pitch') + xlab('') + ylab(' (z-score)') #+ theme(legend.position="none")
res.intens.plot
# ggsave(file='../plots/IntensityResidualized.pdf',width=3,height=3)

pdf("../plots/IntensityCombined.pdf",width=5,height=3, onefile=FALSE)
grid_arrange_shared_legend(rel.intens.plot, res.intens.plot, ncol = 2, nrow = 1)
dev.off()

intensityModel=lmer(relative_intensity~Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||Item)+(Decl.vs.Inter*Left.vs.Right*(Wide.vs.Narrow+First.vs.Late+Second.vs.Third)||participant),data=subsetB,na.action=na.exclude)
summary(intensityModel)

intensityModelFirst=lmer(relative_intensity~Decl.vs.Inter*Left.vs.Right+(Decl.vs.Inter*Left.vs.Right||Item)+(Decl.vs.Inter*Left.vs.Right||participant),data=accuB,na.action=na.exclude)
summary(intensityModelFirst)

sink("../models/modelsIntensity.tex", append=FALSE, split=FALSE)
texreg(list(intensityModel,intensityModelFirst),custom.model.names=c("All","Initial Focus"),naive=TRUE,single.row = T,include.aic=F,include.deviance=F,include.bic=F, include.loglik=F,include.variance=F,dcolumn=T, include.nobs=F, include.groups=F,,caption = "Mixed Effects Regression Models for the relativized intensity of word B.",use.packages=F,float.pos="h!",fontsize = "footnotesize",label="modelPitch")
sink()



dd2 <- dd2[!is.na(dd2$pitch),]



# pca
# PCA for  duration and intensity
pc = princomp(data.frame(duration=dd2$relative_duration,intensity=dd2$relative_intensity), cor=T)
pc$loadings
dd2$DurationIntensityComp1=pc$scores[,1]
dd2$DurationIntensityComp2=pc$scores[,2]

# Effect of Decorrelated Duration/Intensity
dur.int.pca1.plot <-ggplot(dd2, aes(x=Position, y=DurationIntensityComp1,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8) + ggtitle('PC1: Orthogonal Duration and Intensity') + theme(plot.title = element_text(size=8, hjust = 0.5)) + xlab('')
ggsave(file='../plots/DurationIntensityPCA1.pdf',width=3,height=3)
#
dur.int.pca2.plot <-ggplot(dd2, aes(x=Position, y=DurationIntensityComp2,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8)  + ggtitle('PC2: Correlated Duration and Intensity') + theme(plot.title = element_text(size=8, hjust = 0.5)) + xlab('')
ggsave(file='../plots/DurationIntensityPCA2.pdf',width=3,height=3)

pdf("../plots/DurationIntensityPCA.pdf",width=5,height=3, onefile=FALSE)
grid_arrange_shared_legend(dur.int.pca1.plot, dur.int.pca2.plot, ncol = 2, nrow = 1)
dev.off()

# PCA for pitch and intensity
dd2=subset(dd2,!is.na(dd2$relative_pitch))
pc = princomp(data.frame(intensity=dd2$relative_pitch,pitch=dd2$relative_intensity), cor=T,na.action=na.omit)
pc$loadings
dd2$PitchIntensityComp1=pc$scores[,1]
dd2$PitchIntensityComp2=pc$scores[,2]
#
# Effect of Decorrelated Pitch/Intensity
pitch.int.pca1.plot <- ggplot(dd2, aes(x=Position, y=PitchIntensityComp1,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8) + ggtitle('PC1: Correlated Pitch and Intensity') + theme(plot.title = element_text(hjust = 0.5)) + xlab('')
ggsave(file='../plots/PitchIntensityPCA1.pdf',width=3,height=3)
#
pitch.int.pca2.plot <- ggplot(dd2, aes(x=Position, y=PitchIntensityComp2,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8)  + ggtitle('PC2: Orthogonal Pitch and Intensity') + theme(plot.title = element_text(hjust = 0.5)) + xlab('')
ggsave(file='../plots/PitchIntensityPCA2.pdf',width=3,height=3)

pdf("../plots/PitchIntensityPCA.pdf",width=5,height=3, onefile=FALSE)
grid_arrange_shared_legend(pitch.int.pca1.plot, pitch.int.pca2.plot, ncol = 2, nrow = 1)
dev.off()



# PCA for pitch and duration
pc = princomp(data.frame(duration=dd2$relative_duration,pitch=dd2$relative_pitch), cor=T)
pc$loadings
dd2$PitchDurationComp1=pc$scores[,1]
dd2$PitchDurationComp2=pc$scores[,2]


# Effect of Decorrelated Pitch/Duration
pitch.dur.pca1.plot <- ggplot(dd2, aes(x=Position, y=PitchDurationComp1,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8) + ggtitle('PC1: Correlated Pitch and Duration') + theme(plot.title = element_text(hjust = 0.5)) + xlab('')
ggsave(file='../plots/PitchDurationPCA1.pdf',width=3,height=3)
#
pitch.dur.pca2.plot <- ggplot(dd2, aes(x=Position, y=PitchDurationComp2,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab(' (z-score)') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=8) + ggtitle('PC2: Orthogonal Pitch and Duration') + theme(plot.title = element_text(hjust = 0.5)) + xlab('')
ggsave(file='../plots/PitchDurationPCA2.pdf',width=3,height=3)

pdf("../plots/PitchDurationPCA.pdf",width=5,height=3, onefile=FALSE)
grid_arrange_shared_legend(pitch.dur.pca1.plot, pitch.dur.pca2.plot, ncol = 2, nrow = 1)
dev.off()

# PCA for pitch and intensity and duration
pc = princomp(data.frame(pitch=arm::rescale(dd2$relative_pitch),intensity=arm::rescale(dd2$relative_intensity),duration=arm::rescale(dd2$relative_duration)), cor=T)
pc$loadings
dd2$PitchIntensityDurationComp1=pc$scores[,1]
dd2$PitchIntensityDurationComp2=pc$scores[,2]
dd2$PitchIntensityDurationComp3=pc$scores[,3]



res.pitch.plot <- ggplot(pos.long1, aes(x=Position, y=Max_F0,shape=Focus)) +
  stat_summary(fun.y=mean, geom="point") +
  #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
  stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) +
  ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Residualized Pitch') + theme(plot.title = element_text(hjust = 0.5)) + ylab('Residualized Pitch') + xlab('') + ylab(' (z-score)') #+ theme(legend.position="none")
res.pitch.plot


## MM version

plotData <- summarySE(brack.long,'relative_pitch', groupvars = c('Position', 'Focus', 'Intonation', 'Constituency'),na.rm = T)
cons.plot<-ggplot(plotData, aes(x=Position, y=relative_pitch,shape=Focus,group=Focus)) +
    geom_point() +
    #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
    geom_line() +
    ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10) + theme(legend.position="none") + ggtitle('Effect of Constituency') + theme(plot.title = element_text(hjust = 0.5),strip.text.y = element_blank()) + ylab('Residualized Pitch') + xlab('')+ scale_y_continuous(breaks = c(-0.25,-0.25,0,0.25,0.25), limits = c(-0.252,0.252))
cons.plot
#ggsave(file='PitchConstituencyResidualized.pdf',width=plotwid,height=plotheight)

#Pitch residualized for predictors other than intonation
ggplot(intonation.long, aes(x=Position, y=relative_pitch,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Effect of Tune') + theme(plot.title = element_text(hjust = 0.5))  + ylab('') + theme(legend.position="none") + xlab('')

#INtensity residualized for predictors other than intonation
ggplot(intonation.long, aes(x=Position, y=Mean_Intensity_relative,shape=Focus))+ stat_summary(fun.y=mean, geom="point")  + stat_summary(fun.y = "mean", geom="line", aes(group=Focus)) + ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10)  + ggtitle('Effect of Tune') + theme(plot.title = element_text(hjust = 0.5))  + ylab('') + theme(legend.position="none") + xlab('')


## MM version

plotData <- summarySE(intonation.long,'relative_pitch', groupvars = c('Position', 'Focus', 'Intonation', 'Constituency'),na.rm = T)
tune.plot<-ggplot(plotData, aes(x=Position, y=relative_pitch,shape=Focus,group=Focus)) +
    geom_point() +
    #stat_summary(fun.data = "mean_cl_boot", geom="errorbar", size=0.6, width=.15) +
    geom_line() +
    ylab('Residualized Pitch') + facet_grid(Intonation ~ Constituency, scales = "fixed") + theme_bw(base_size=10) + theme(legend.position="none") + ggtitle('Effect of Tune') + theme(plot.title = element_text(hjust = 0.5), axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title.y = element_blank(),strip.text.y = element_blank()) + xlab('') + scale_y_continuous(breaks = c(-0.5,-0.25,0,0.25,0.5), limits = c(-0.52,0.52))
tune.plot
#ggsave(file='PitchIntonationResidualized.pdf',width=plotwid,height=plotheight)


